{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a9043f",
   "metadata": {},
   "source": [
    "# Notebook 01: FIRMS Fire Detection Data Extraction (Europe)\n",
    "\n",
    "This notebook retrieves and prepares European fire detection data from the NASA FIRMS API for downstream spatial analysis.\n",
    "\n",
    "## Contents\n",
    "1. Project setup\n",
    "2. Configuration and parameters\n",
    "3. FIRMS API request construction\n",
    "4. Multi-year data retrieval\n",
    "5. Output validation and storage\n",
    "\n",
    "## Objectives of this notebook\n",
    "- Download detection-level fire points for Europe from NASA FIRMS\n",
    "- Preserve latitude and longitude for spatial mapping\n",
    "- Save a multi-year raw detection dataset for:\n",
    "  - Spatial fire-risk analysis\n",
    "  - Overlay with protected areas\n",
    "  - Future prediction modelling\n",
    "\n",
    "## Inputs\n",
    "- FIRMS API configuration JSON\n",
    "- VIIRS_SNPP_SP (science-grade fire product)\n",
    "\n",
    "## Outputs\n",
    "- Raw detection dataset (`data/raw/*.csv.gz`)\n",
    "- Extraction log file\n",
    "\n",
    "## Notes\n",
    "- Data are requested in multi-day windows for efficiency.\n",
    "- Each detection retains its true acquisition date (`acq_date`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d14f74",
   "metadata": {},
   "source": [
    "## 1. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b4661-2edc-4849-a464-378f153cf0b4",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Importing the libraries required for this notebook:\n",
    "\n",
    "- The `pathlib` library is used to manage folder structures and file paths clearly.\n",
    "- `Pandas` is used for structuring and analysing tabular data.\n",
    "- The `io` module is used to enable pandas to read CSV data directly from API responses without saving temporary files.\n",
    "- `Matplotlib` is used for creating exploratory visualisations.\n",
    "- The `requests` library is used to retrieve data from NASA’s FIRMS API.\n",
    "- The `json` library is used to load API request parameters from a configuration file.\n",
    "- The `datetime` module is used for handling date-based tasks when looping through time periods.\n",
    "- The `time` module is used to introduce short pauses between API requests to avoid exceeding transaction limits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daea74e1-9681-4317-b974-7d491c74b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import io \n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed1dd3",
   "metadata": {},
   "source": [
    "## Project directory\n",
    "The code below sets the project root directory, defines standard project folders, and loads the FIRMS API configuration file to ensure reproducible data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7eccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\Surface\\Documents\\capstone_project\n",
      "Config loaded successfully\n",
      "Date range: 2020-10-01 to 2025-09-30\n",
      "Raw data will be saved to: c:\\Users\\Surface\\Documents\\capstone_project\\data\\raw\\europe_firms_viirs_snpp_sp_2020_2025.csv.gz\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Set project root (moves up from /notebooks)\n",
    "PROJECT_DIR = Path.cwd()\n",
    "if PROJECT_DIR.name == \"notebooks\":\n",
    "    PROJECT_DIR = PROJECT_DIR.parent\n",
    "\n",
    "print(\"Project root:\", PROJECT_DIR)\n",
    "\n",
    "# Define main folders\n",
    "RAW_DIR = PROJECT_DIR / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = PROJECT_DIR / \"data\" / \"processed\"\n",
    "OUTPUTS_DIR = PROJECT_DIR / \"outputs\"\n",
    "FIGURES_DIR = OUTPUTS_DIR / \"figures\"\n",
    "TABLES_DIR = OUTPUTS_DIR / \"tables\"\n",
    "RESULTS_DIR = OUTPUTS_DIR / \"model_results\"\n",
    "CONFIG_DIR = PROJECT_DIR / \"config\"\n",
    "\n",
    "# Create folders if they don’t exist\n",
    "for folder in [RAW_DIR, PROCESSED_DIR, FIGURES_DIR, TABLES_DIR, RESULTS_DIR, CONFIG_DIR]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load configuration file\n",
    "config_path = CONFIG_DIR / \"firms_europe_full.json\"\n",
    "\n",
    "with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Define output path for raw FIRMS data\n",
    "out_path = RAW_DIR / Path(config[\"output_raw_csv_gz\"]).name\n",
    "\n",
    "print(\"Config loaded successfully\")\n",
    "print(\"Date range:\", config[\"start_date\"], \"to\", config[\"end_date\"])\n",
    "print(\"Raw data will be saved to:\", out_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3c420",
   "metadata": {},
   "source": [
    "## 2. Configuration and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd1ecdb-4576-4024-b3e2-8115bd1cded3",
   "metadata": {},
   "source": [
    "## Define analysis date range\n",
    "\n",
    "The analysis uses VIIRS_SNPP_SP (science-grade standard processing) FIRMS fire detection data.\n",
    "\n",
    "To identify robust wildfire patterns, a **five-year period from October 2020 to September 2025** is analysed.  \n",
    "This range was selected to provide:\n",
    "\n",
    "- Multiple complete annual fire seasons for trend comparison  \n",
    "- Fully published, quality-controlled satellite observations (Data from 01.09.25 onwards is unverified).\n",
    "- Consistent temporal coverage across all years  \n",
    "- Avoidance of data gaps affecting very recent unreleased data  \n",
    "\n",
    "Using a multi-year window strengthens the reliability of seasonal trend detection and supports more confident interpretation of changing wildfire behaviour across Europe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b90fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis period: 2020-10-01 to 2025-09-30\n"
     ]
    }
   ],
   "source": [
    "print(\"Analysis period:\", config[\"start_date\"], \"to\", config[\"end_date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435033b-1cb0-42f3-b48c-61730748c300",
   "metadata": {},
   "source": [
    "## Retrieve detection-level fire points for Europe\n",
    "\n",
    "The FIRMS API returns a CSV containing **individual fire detections** for a given date window and region.  \n",
    "Full detection records are kept (including **latitude and longitude**) so I can:\n",
    "\n",
    "- map fires across Europe\n",
    "- overlay detections with protected areas\n",
    "- build spatial features for prediction modelling\n",
    "\n",
    "A helper function is created to:\n",
    "\n",
    "- construct the FIRMS API request URL for a given start date\n",
    "- request data from the API\n",
    "- load the returned CSV into a pandas DataFrame\n",
    "- add basic metadata (query start date, source, bbox)\n",
    "- return the **full detection dataset** (not aggregated counts)\n",
    "\n",
    "Note: Daily fire counts can still be created later by grouping the detection data by `acq_date`.\n",
    "Note: The geographic co-ordinates for Europe are set to: **-31.5, 34, 40.5, 72** for this FIRMS extraction plus both overlay datasets in further notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d64b144-ee2c-4596-8acb-145ab2d32eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_firms_url(date_str: str) -> str:\n",
    "    base = config[\"api_base_url\"].rstrip(\"/\")\n",
    "    key = config[\"api_key\"]\n",
    "    source = config[\"source\"]\n",
    "    area = config[\"area\"]\n",
    "    day_range = config[\"day_range\"]\n",
    "    return f\"{base}/{key}/{source}/{area}/{day_range}/{date_str}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8641b9",
   "metadata": {},
   "source": [
    "## 3. FIRMS API request construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ebbd089-cbe5-40ad-a663-c7b962eb770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fire_detections(date_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch FIRMS detections for [date_str .. date_str + day_range - 1].\n",
    "    Returns a dataframe of detection points (includes lat/lon).\n",
    "    \"\"\"\n",
    "    url = build_firms_url(date_str)\n",
    "    r = requests.get(url, timeout=120)\n",
    "    text = (r.text or \"\").strip()\n",
    "\n",
    "    # Added stage to counter prior FIRMS text errors\n",
    "    if r.status_code != 200 or len(text) == 0 or text.lower().startswith(\"invalid\"):\n",
    "        print(f\"Failed {date_str} | HTTP {r.status_code} | msg: {(text[:120] if text else 'EMPTY')}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # I convert the API response text into a DataFrame.\n",
    "    # If no detections exist, pandas returns an empty DataFrame.\n",
    "    df = pd.read_csv(io.StringIO(text))\n",
    "\n",
    "\n",
    "    # Add query metadata (helpful for auditing)\n",
    "    df[\"query_start_date\"] = date_str\n",
    "    df[\"source\"] = config[\"source\"]\n",
    "    df[\"bbox\"] = config[\"area\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98ecb8-1968-4a7d-9bba-3ad05e8f4544",
   "metadata": {},
   "source": [
    "### Testing and Validation Steps\n",
    "\n",
    "Before running the full data extraction process, I carried out a series of small test checks to confirm that my API connection and data-handling logic worked as expected.\n",
    "\n",
    "I first tested the FIRMS URL builder function using a single known date to confirm that the generated request URL matched the expected format. I then sent a test API request for an individual date and checked the response status code to confirm that the connection to the FIRMS service was successful.\n",
    "\n",
    "Next, I inspected the returned text content to verify that valid CSV data was being received. I tested how my code behaved when detections were present and when no detections were returned, confirming that pandas correctly created an empty DataFrame in the no-data case.\n",
    "\n",
    "Finally, I verified that additional metadata columns (query date, data source, and bounding box) were being added correctly to the output DataFrame.\n",
    "\n",
    "Once these checks were complete and the functions behaved as intended, I removed the individual test code cells and proceeded with the full automated data collection workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5073bd",
   "metadata": {},
   "source": [
    "## 4. Multi-year data retrieval & storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9d93b",
   "metadata": {},
   "source": [
    "### Full FIRMS Data Extraction (Multi-Year Run)\n",
    "\n",
    "In this section, I run the full FIRMS data extraction across my configured multi-year period. My configuration file has been updated to cover the complete five-year extraction range. I have replaced the earlier test code cells with markdown to keep the notebook tidy and avoid confusion in the final workflow.\n",
    "\n",
    "The script below loops through the date range in multi-day windows and downloads detection-level FIRMS fire points for Europe. Each API response is processed and appended into a single gzip-compressed CSV file in my raw data folder.\n",
    "\n",
    "This output dataset will be used in the next stages of the project for:\n",
    "\n",
    "spatial mapping of fire detections across Europe\n",
    "\n",
    "overlaying fire locations with protected area boundaries\n",
    "\n",
    "feature engineering and prediction modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0225c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full FIRMS extraction run (will not run now as API KEY has been removed from json for Capstone Project Submission).\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"Starting FIRMS extraction: {config['start_date']} to {config['end_date']}\")\n",
    "print(f\"Saving output to: {out_path}\")\n",
    "\n",
    "start = pd.to_datetime(config[\"start_date\"])\n",
    "end = pd.to_datetime(config[\"end_date\"])\n",
    "day_range = int(config[\"day_range\"])\n",
    "\n",
    "# Generate window start dates\n",
    "window_starts = pd.date_range(start, end, freq=f\"{day_range}D\")\n",
    "\n",
    "# Track whether header has been written\n",
    "wrote_header = out_path.exists()\n",
    "total_rows = 0\n",
    "\n",
    "for dt in window_starts:\n",
    "    date_str = dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df_win = get_fire_detections(date_str)\n",
    "\n",
    "    if df_win.empty:\n",
    "        print(f\"{date_str} → no data\")\n",
    "        continue\n",
    "\n",
    "    df_win.to_csv(\n",
    "        out_path,\n",
    "        mode=\"a\",\n",
    "        index=False,\n",
    "        header=not wrote_header,\n",
    "        compression=\"gzip\"\n",
    "    )\n",
    "\n",
    "    wrote_header = True\n",
    "    total_rows += len(df_win)\n",
    "\n",
    "    print(f\"{date_str} → {len(df_win)} rows saved\")\n",
    "\n",
    "    time.sleep(0.8)  # small pause to respect API limits\n",
    "\n",
    "print(f\"\\nExtraction complete. Total rows saved: {total_rows}\")\n",
    "print(f\"File location: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cdeef8",
   "metadata": {},
   "source": [
    "## 5. Output validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f13872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows loaded: 2680935\n",
      "Columns: Index(['latitude', 'longitude', 'bright_ti4', 'scan', 'track', 'acq_date',\n",
      "       'acq_time', 'satellite', 'instrument', 'confidence'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bright_ti4</th>\n",
       "      <th>scan</th>\n",
       "      <th>track</th>\n",
       "      <th>acq_date</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>satellite</th>\n",
       "      <th>instrument</th>\n",
       "      <th>confidence</th>\n",
       "      <th>version</th>\n",
       "      <th>bright_ti5</th>\n",
       "      <th>frp</th>\n",
       "      <th>daynight</th>\n",
       "      <th>type</th>\n",
       "      <th>query_start_date</th>\n",
       "      <th>source</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.35962</td>\n",
       "      <td>12.37329</td>\n",
       "      <td>299.82</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>279.14</td>\n",
       "      <td>1.05</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>VIIRS_SNPP_SP</td>\n",
       "      <td>-11,34,31,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.65267</td>\n",
       "      <td>30.28964</td>\n",
       "      <td>296.89</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>278.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>VIIRS_SNPP_SP</td>\n",
       "      <td>-11,34,31,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.06306</td>\n",
       "      <td>28.13327</td>\n",
       "      <td>301.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>280.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>VIIRS_SNPP_SP</td>\n",
       "      <td>-11,34,31,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.38455</td>\n",
       "      <td>28.46527</td>\n",
       "      <td>301.06</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>278.51</td>\n",
       "      <td>0.94</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>VIIRS_SNPP_SP</td>\n",
       "      <td>-11,34,31,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.38541</td>\n",
       "      <td>28.45637</td>\n",
       "      <td>295.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>278.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>VIIRS_SNPP_SP</td>\n",
       "      <td>-11,34,31,72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude  bright_ti4  scan  track    acq_date  acq_time  \\\n",
       "0  58.35962   12.37329      299.82  0.59   0.70  2020-10-01         0   \n",
       "1  58.65267   30.28964      296.89  0.44   0.39  2020-10-01         0   \n",
       "2  59.06306   28.13327      301.22  0.51   0.41  2020-10-01         0   \n",
       "3  59.38455   28.46527      301.06  0.50   0.41  2020-10-01         0   \n",
       "4  59.38541   28.45637      295.39  0.50   0.41  2020-10-01         0   \n",
       "\n",
       "  satellite instrument confidence  version  bright_ti5   frp daynight  type  \\\n",
       "0         N      VIIRS          n        2      279.14  1.05        N     2   \n",
       "1         N      VIIRS          n        2      278.56  0.60        N     0   \n",
       "2         N      VIIRS          n        2      280.91  0.98        N     2   \n",
       "3         N      VIIRS          n        2      278.51  0.94        N     2   \n",
       "4         N      VIIRS          n        2      278.94  0.94        N     0   \n",
       "\n",
       "  query_start_date         source          bbox  \n",
       "0       2020-10-01  VIIRS_SNPP_SP  -11,34,31,72  \n",
       "1       2020-10-01  VIIRS_SNPP_SP  -11,34,31,72  \n",
       "2       2020-10-01  VIIRS_SNPP_SP  -11,34,31,72  \n",
       "3       2020-10-01  VIIRS_SNPP_SP  -11,34,31,72  \n",
       "4       2020-10-01  VIIRS_SNPP_SP  -11,34,31,72  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = pd.read_csv(out_path, compression=\"gzip\")\n",
    "print(\"Rows loaded:\", len(df_check))\n",
    "print(\"Columns:\", df_check.columns[:10])\n",
    "df_check.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c3fa3",
   "metadata": {},
   "source": [
    "## End of Notebook 01\n",
    "\n",
    "The full five-year FIRMS detection-level fire dataset for Europe has now been successfully extracted and saved to the raw data folder.  \n",
    "\n",
    "This dataset contains spatial fire detection points (latitude and longitude) along with temporal and intensity attributes, and forms the foundation for all subsequent analysis.\n",
    "\n",
    "The next notebook focuses on data inspection, cleaning, and spatial exploratory analysis of these fire detections.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
